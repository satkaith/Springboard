{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Springboard Apps project - Tier 1 - Cleaning, transforming and visualizing\n",
    "\n",
    "Welcome to the final project of this Springboard prep course! To give you a taste of your future career, we're going to walk through exactly the kind of notebook that you'd write as a data scientist. In the process, we'll be sure to signpost the general framework for our investigation - the Data Science Pipeline - as well as give reasons for why we're doing what we're doing.\n",
    "\n",
    "**Brief**\n",
    "\n",
    "Did Apple Store apps receive better reviews than Google Play apps?\n",
    "\n",
    "## Stages of the project\n",
    "\n",
    "1. Sourcing and loading \n",
    "    * Load the two datasets\n",
    "    * Pick the columns that we are going to work with \n",
    "    * Subsetting the data on this basis \n",
    " \n",
    " \n",
    "2. Cleaning, transforming and visualizing\n",
    "    * Check the data types and fix them\n",
    "    * Add a `platform` column to both the `Apple` and the `Google` dataframes\n",
    "    * Changing the column names to prepare for a join \n",
    "    * Join the two data sets\n",
    "    * Eliminate the `NaN` values\n",
    "    * Filter only those apps that have been reviewed at least once\n",
    "    * Summarize the data visually and analytically (by the column `platform`)  \n",
    "  \n",
    "  \n",
    "3. Modelling \n",
    "    * Hypothesis formulation\n",
    "    * Getting the distribution of the data\n",
    "    * Permutation test \n",
    "\n",
    "\n",
    "4. Evaluating and concluding \n",
    "    * What is our conclusion?\n",
    "    * What is our decision?\n",
    "    * Other models we could have used. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries\n",
    "\n",
    "In this case we are going to import pandas, numpy, scipy, random and matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "# scipi is a library for statistical tests and visualizations \n",
    "from scipy import stats\n",
    "# random enables us to generate random numbers\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 -  Sourcing and loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Source and load the data\n",
    "Let's download the data from Kaggle. Kaggle is a fantastic resource: a kind of social medium for data scientists, it boasts projects, datasets and news on the freshest libraries and technologies all in one place. The data from the Apple Store can be found [here](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps) and the data from Google Store can be found [here](https://www.kaggle.com/lava18/google-play-store-apps).\n",
    "Download the datasets and save them in your working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Category</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Size</th>\n",
       "      <th>Installs</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Content Rating</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Last Updated</th>\n",
       "      <th>Current Ver</th>\n",
       "      <th>Android Ver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Photo Editor &amp; Candy Camera &amp; Grid &amp; ScrapBook</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.1</td>\n",
       "      <td>159</td>\n",
       "      <td>19M</td>\n",
       "      <td>10,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>Art &amp; Design</td>\n",
       "      <td>January 7, 2018</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coloring book moana</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>3.9</td>\n",
       "      <td>967</td>\n",
       "      <td>14M</td>\n",
       "      <td>500,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>Art &amp; Design;Pretend Play</td>\n",
       "      <td>January 15, 2018</td>\n",
       "      <td>2.0.0</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U Launcher Lite – FREE Live Cool Themes, Hide ...</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.7</td>\n",
       "      <td>87510</td>\n",
       "      <td>8.7M</td>\n",
       "      <td>5,000,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>Art &amp; Design</td>\n",
       "      <td>August 1, 2018</td>\n",
       "      <td>1.2.4</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 App        Category  Rating  \\\n",
       "0     Photo Editor & Candy Camera & Grid & ScrapBook  ART_AND_DESIGN     4.1   \n",
       "1                                Coloring book moana  ART_AND_DESIGN     3.9   \n",
       "2  U Launcher Lite – FREE Live Cool Themes, Hide ...  ART_AND_DESIGN     4.7   \n",
       "\n",
       "  Reviews  Size    Installs  Type Price Content Rating  \\\n",
       "0     159   19M     10,000+  Free     0       Everyone   \n",
       "1     967   14M    500,000+  Free     0       Everyone   \n",
       "2   87510  8.7M  5,000,000+  Free     0       Everyone   \n",
       "\n",
       "                      Genres      Last Updated Current Ver   Android Ver  \n",
       "0               Art & Design   January 7, 2018       1.0.0  4.0.3 and up  \n",
       "1  Art & Design;Pretend Play  January 15, 2018       2.0.0  4.0.3 and up  \n",
       "2               Art & Design    August 1, 2018       1.2.4  4.0.3 and up  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that the files are saved, we want to load them into Python using read_csv and pandas.\n",
    "\n",
    "# Create a variable called google, and store in it the path of the csv file that contains your google dataset. \n",
    "# If your dataset is in the same folder as this notebook, the path will simply be the name of the file. \n",
    "# As suggested by my mentor, I used the next step directly to read the CSV file, instead of assigning the variable for \"google = _ _ _\"\n",
    "\n",
    "# Read the csv file into a data frame called Google using the read_csv() pandas method.\n",
    "Google = pd.read_csv('googleplaystore.csv')\n",
    "\n",
    "# Using the head() pandas method, observe the first three entries.\n",
    "Google.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>currency</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>281656475</td>\n",
       "      <td>PAC-MAN Premium</td>\n",
       "      <td>100788224</td>\n",
       "      <td>USD</td>\n",
       "      <td>3.99</td>\n",
       "      <td>21292</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3.5</td>\n",
       "      <td>4+</td>\n",
       "      <td>Games</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>281796108</td>\n",
       "      <td>Evernote - stay organized</td>\n",
       "      <td>158578688</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>161065</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.2.2</td>\n",
       "      <td>4+</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>281940292</td>\n",
       "      <td>WeatherBug - Local Weather, Radar, Maps, Alerts</td>\n",
       "      <td>100524032</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>188583</td>\n",
       "      <td>2822</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0.0</td>\n",
       "      <td>4+</td>\n",
       "      <td>Weather</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         id                                       track_name  \\\n",
       "0           1  281656475                                  PAC-MAN Premium   \n",
       "1           2  281796108                        Evernote - stay organized   \n",
       "2           3  281940292  WeatherBug - Local Weather, Radar, Maps, Alerts   \n",
       "\n",
       "   size_bytes currency  price  rating_count_tot  rating_count_ver  \\\n",
       "0   100788224      USD   3.99             21292                26   \n",
       "1   158578688      USD   0.00            161065                26   \n",
       "2   100524032      USD   0.00            188583              2822   \n",
       "\n",
       "   user_rating  user_rating_ver    ver cont_rating   prime_genre  \\\n",
       "0          4.0              4.5  6.3.5          4+         Games   \n",
       "1          4.0              3.5  8.2.2          4+  Productivity   \n",
       "2          3.5              4.5  5.0.0          4+       Weather   \n",
       "\n",
       "   sup_devices.num  ipadSc_urls.num  lang.num  vpp_lic  \n",
       "0               38                5        10        1  \n",
       "1               37                5        23        1  \n",
       "2               37                5         3        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a variable called apple, and store in it the path of the csv file that contains your apple dataset. \n",
    "# As suggested by my mentor, I used the next step directly to read the CSV file, instead of assigning the variable for \"apple = _ _ _\" \n",
    "\n",
    "# Read the csv file into a pandas DataFrame object called Apple.\n",
    "Apple = pd.read_csv('AppleStore.csv') \n",
    "\n",
    "# Observe the first three entries like you did with your other data. \n",
    "Apple.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Pick the columns we'll work with\n",
    "\n",
    "From the documentation of these datasets, we can infer that the most appropriate columns to answer the brief are:\n",
    "\n",
    "1. Google:\n",
    "    * `Category` # Do we need this?\n",
    "    * `Rating`\n",
    "    * `Reviews`\n",
    "    * `Price` (maybe)\n",
    "2. Apple:    \n",
    "    * `prime_genre` # Do we need this?\n",
    "    * `user_rating` \n",
    "    * `rating_count_tot`\n",
    "    * `price` (maybe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Subsetting accordingly\n",
    "\n",
    "Let's select only those columns that we want to work with from both datasets. We'll overwrite the subsets in the original variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>3.9</td>\n",
       "      <td>967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.7</td>\n",
       "      <td>87510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category  Rating Reviews Price\n",
       "0  ART_AND_DESIGN     4.1     159     0\n",
       "1  ART_AND_DESIGN     3.9     967     0\n",
       "2  ART_AND_DESIGN     4.7   87510     0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset our DataFrame object Google by selecting just the variables ['Category', 'Rating', 'Reviews', 'Price']\n",
    "Google [['Category', 'Rating', 'Reviews', 'Price']]\n",
    "\n",
    "# Check the first three entries\n",
    "Google.loc[[0, 1, 2],['Category', 'Rating', 'Reviews', 'Price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Games</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21292</td>\n",
       "      <td>3.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Productivity</td>\n",
       "      <td>4.0</td>\n",
       "      <td>161065</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weather</td>\n",
       "      <td>3.5</td>\n",
       "      <td>188583</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prime_genre  user_rating  rating_count_tot  price\n",
       "0         Games          4.0             21292   3.99\n",
       "1  Productivity          4.0            161065   0.00\n",
       "2       Weather          3.5            188583   0.00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same with our Apple object, selecting just the variables ['prime_genre', 'user_rating', 'rating_count_tot', 'price']\n",
    "Apple [['prime_genre', 'user_rating', 'rating_count_tot', 'price']]\n",
    "\n",
    "# Let's check the first three entries\n",
    "Apple.loc[[0,1,2],['prime_genre', 'user_rating', 'rating_count_tot', 'price']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 -  Cleaning, transforming and visualizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Check the data types for both Apple and Google, and fix them\n",
    "\n",
    "Types are crucial for data science in Python. Let's determine whether the variables we selected in the previous section belong to the types they should do, or whether there are any errors here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            int64\n",
       "id                    int64\n",
       "track_name           object\n",
       "size_bytes            int64\n",
       "currency             object\n",
       "price               float64\n",
       "rating_count_tot      int64\n",
       "rating_count_ver      int64\n",
       "user_rating         float64\n",
       "user_rating_ver     float64\n",
       "ver                  object\n",
       "cont_rating          object\n",
       "prime_genre          object\n",
       "sup_devices.num       int64\n",
       "ipadSc_urls.num       int64\n",
       "lang.num              int64\n",
       "vpp_lic               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the dtypes feature of pandas DataFrame objects, check out the data types within our Apple dataframe.\n",
    "# Are they what you expect?\n",
    "Apple.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is looking healthy. But what about our Google data frame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "App                object\n",
       "Category           object\n",
       "Rating            float64\n",
       "Reviews            object\n",
       "Size               object\n",
       "Installs           object\n",
       "Type               object\n",
       "Price              object\n",
       "Content Rating     object\n",
       "Genres             object\n",
       "Last Updated       object\n",
       "Current Ver        object\n",
       "Android Ver        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the same dtypes feature, check out the data types of our Google dataframe. \n",
    "Google.dtypes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird. The data type for the column 'Price' is 'object', not a numeric data type like a float or an integer. Let's investigate the unique values of this column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '$4.99', '$3.99', '$6.99', '$1.49', '$2.99', '$7.99', '$5.99',\n",
       "       '$3.49', '$1.99', '$9.99', '$7.49', '$0.99', '$9.00', '$5.49',\n",
       "       '$10.00', '$24.99', '$11.99', '$79.99', '$16.99', '$14.99',\n",
       "       '$1.00', '$29.99', '$12.99', '$2.49', '$10.99', '$1.50', '$19.99',\n",
       "       '$15.99', '$33.99', '$74.99', '$39.99', '$3.95', '$4.49', '$1.70',\n",
       "       '$8.99', '$2.00', '$3.88', '$25.99', '$399.99', '$17.99',\n",
       "       '$400.00', '$3.02', '$1.76', '$4.84', '$4.77', '$1.61', '$2.50',\n",
       "       '$1.59', '$6.49', '$1.29', '$5.00', '$13.99', '$299.99', '$379.99',\n",
       "       '$37.99', '$18.99', '$389.99', '$19.90', '$8.49', '$1.75',\n",
       "       '$14.00', '$4.85', '$46.99', '$109.99', '$154.99', '$3.08',\n",
       "       '$2.59', '$4.80', '$1.96', '$19.40', '$3.90', '$4.59', '$15.46',\n",
       "       '$3.04', '$4.29', '$2.60', '$3.28', '$4.60', '$28.99', '$2.95',\n",
       "       '$2.90', '$1.97', '$200.00', '$89.99', '$2.56', '$30.99', '$3.61',\n",
       "       '$394.99', '$1.26', 'Everyone', '$1.20', '$1.04'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the unique() pandas method on the Price column to check its unique values. \n",
    "Google['Price'].unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Aha! Fascinating. There are actually two issues here. \n",
    "\n",
    "- Firstly, there's a price called `Everyone`. That is a massive mistake! \n",
    "- Secondly, there are dollar symbols everywhere! \n",
    "\n",
    "\n",
    "Let's address the first issue first. Let's check the datapoints that have the price value `Everyone`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Category</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Size</th>\n",
       "      <th>Installs</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Content Rating</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Last Updated</th>\n",
       "      <th>Current Ver</th>\n",
       "      <th>Android Ver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10472</th>\n",
       "      <td>Life Made WI-Fi Touchscreen Photo Frame</td>\n",
       "      <td>1.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0M</td>\n",
       "      <td>1,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>February 11, 2018</td>\n",
       "      <td>1.0.19</td>\n",
       "      <td>4.0 and up</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           App Category  Rating Reviews  \\\n",
       "10472  Life Made WI-Fi Touchscreen Photo Frame      1.9    19.0    3.0M   \n",
       "\n",
       "         Size Installs Type     Price Content Rating             Genres  \\\n",
       "10472  1,000+     Free    0  Everyone            NaN  February 11, 2018   \n",
       "\n",
       "      Last Updated Current Ver Android Ver  \n",
       "10472       1.0.19  4.0 and up         NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check which data points have the value 'Everyone' for the 'Price' column by subsetting our Google dataframe.\n",
    "\n",
    "# Subset the Google dataframe on the price column. \n",
    "# To be sure: you want to pick out just those rows whose value for the 'Price' column is just 'Everyone'. \n",
    "Google[Google['Price']=='Everyone']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully, it's just one row. We've gotta get rid of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '$4.99', '$3.99', '$6.99', '$1.49', '$2.99', '$7.99', '$5.99',\n",
       "       '$3.49', '$1.99', '$9.99', '$7.49', '$0.99', '$9.00', '$5.49',\n",
       "       '$10.00', '$24.99', '$11.99', '$79.99', '$16.99', '$14.99',\n",
       "       '$1.00', '$29.99', '$12.99', '$2.49', '$10.99', '$1.50', '$19.99',\n",
       "       '$15.99', '$33.99', '$74.99', '$39.99', '$3.95', '$4.49', '$1.70',\n",
       "       '$8.99', '$2.00', '$3.88', '$25.99', '$399.99', '$17.99',\n",
       "       '$400.00', '$3.02', '$1.76', '$4.84', '$4.77', '$1.61', '$2.50',\n",
       "       '$1.59', '$6.49', '$1.29', '$5.00', '$13.99', '$299.99', '$379.99',\n",
       "       '$37.99', '$18.99', '$389.99', '$19.90', '$8.49', '$1.75',\n",
       "       '$14.00', '$4.85', '$46.99', '$109.99', '$154.99', '$3.08',\n",
       "       '$2.59', '$4.80', '$1.96', '$19.40', '$3.90', '$4.59', '$15.46',\n",
       "       '$3.04', '$4.29', '$2.60', '$3.28', '$4.60', '$28.99', '$2.95',\n",
       "       '$2.90', '$1.97', '$200.00', '$89.99', '$2.56', '$30.99', '$3.61',\n",
       "       '$394.99', '$1.26', '$1.20', '$1.04'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's eliminate that row. \n",
    "\n",
    "# Subset our Google dataframe to pick out just those rows whose value for the 'Price' column is NOT 'Everyone'. \n",
    "# Reassign that subset to the Google variable. \n",
    "# You can do this in two lines or one. Your choice! \n",
    "Google = Google[Google['Price'] != 'Everyone']\n",
    "\n",
    "# Check again the unique values of Google\n",
    "Google['Price'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second problem remains: I'm seeing dollar symbols when I close my eyes! (And not in a good way). \n",
    "\n",
    "This is a problem because Python actually considers these values strings. So we can't do mathematical and statistical operations on them until we've made them into numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a variable called nosymb.\n",
    "# This variable will take the Price column of Google and apply the str.replace() method. \n",
    "# Remember: we want to find '$' and replace it with nothing, so we'll have to write approrpiate arguments to the method to achieve this. \n",
    "nosymb = Google['Price'].str.replace('$','')\n",
    "\n",
    "# Now we need to do two things:\n",
    "# i. Make the values in the nosymb variable numeric using the to_numeric() pandas method.\n",
    "# ii. Assign this new set of numeric, dollar-sign-less values to Google['Price']. \n",
    "# You can do this in one line if you wish.\n",
    "Google['Price'] = pd.to_numeric(nosymb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the data types for our Google dataframe again, to verify that the 'Price' column really is numeric now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "App                object\n",
       "Category           object\n",
       "Rating            float64\n",
       "Reviews            object\n",
       "Size               object\n",
       "Installs           object\n",
       "Type               object\n",
       "Price             float64\n",
       "Content Rating     object\n",
       "Genres             object\n",
       "Last Updated       object\n",
       "Current Ver        object\n",
       "Android Ver        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the function dtypes. \n",
    "Google.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the column `Reviews` is still an object column. We actually need this column to be a numeric column, too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Reviews' column to a numeric data type. \n",
    "# Use the method pd.to_numeric(), and save the result in the same column.\n",
    "Google['Reviews'] = pd.to_numeric(Google['Reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "App                object\n",
       "Category           object\n",
       "Rating            float64\n",
       "Reviews             int64\n",
       "Size               object\n",
       "Installs           object\n",
       "Type               object\n",
       "Price             float64\n",
       "Content Rating     object\n",
       "Genres             object\n",
       "Last Updated       object\n",
       "Current Ver        object\n",
       "Android Ver        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the data types of Google again\n",
    "Google.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Add a `platform` column to both the `Apple` and the `Google` dataframes\n",
    "Let's add a new column to both dataframe objects called `platform`: all of its values in the Google dataframe will be just 'google', and all of its values for the Apple dataframe will be just 'apple'. \n",
    "\n",
    "The reason we're making this column is so that we can ultimately join our Apple and Google data together, and actually test out some hypotheses to solve the problem in our brief. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column called 'platform' in both the Apple and Google dataframes. \n",
    "# Add the value 'apple' and the value 'google' as appropriate. \n",
    "# Note: I tested both Apple and Google dataframes one-by-one to observe the results.  \n",
    "Apple['platform'] = 'apple'\n",
    "#Tested Apple to observe the results\n",
    "\n",
    "Google['platform'] = 'google'#Tested Google to observe the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Changing the column names to prepare for our join of the two datasets \n",
    "Since the easiest way to join two datasets is if they have both:\n",
    "- the same number of columns\n",
    "- the same column names\n",
    "we need to rename the columns of `Apple` so that they're the same as the ones of `Google`, or vice versa.\n",
    "\n",
    "In this case, we're going to change the `Apple` columns names to the names of the `Google` columns. \n",
    "\n",
    "This is an important step to unify the two datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable called old_names where you'll store the column names of the Apple dataframe. \n",
    "# Use the feature .columns.\n",
    "old_names = Apple.columns\n",
    "\n",
    "# Create a variable called new_names where you'll store the column names of the Google dataframe. \n",
    "new_names = Google.columns\n",
    "\n",
    "# Use the rename() DataFrame method to change the columns names. \n",
    "# In the columns parameter of the rename() method, use this construction: dict(zip(old_names,new_names)).\n",
    "Apple = Apple.rename(columns = dict(zip(old_names,new_names)))# Tested Apple dataframe to observe the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d. Join the two datasets \n",
    "Let's combine the two datasets into a single data frame called `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Size',\n",
       " 'Price',\n",
       " 'Installs',\n",
       " 'Last Updated',\n",
       " 'platform',\n",
       " 'Category',\n",
       " 'lang.num',\n",
       " 'Type',\n",
       " 'Rating',\n",
       " 'Reviews',\n",
       " 'App',\n",
       " 'platform']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use the append() method to append Apple to Google. \n",
    "# Make Apple the first parameter of append(), and make the second parameter just: ignore_index = True.\n",
    "df = Apple.append(Apple, ignore_index = True)\n",
    "# Tested df dataframe to observe the results\n",
    "\n",
    "# Using the sample() method with the number 12 passed to it, check 12 random points of your dataset.\n",
    "random.sample(list(df), 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2e. Eliminate the NaN values\n",
    "\n",
    "As you can see there are some `NaN` values. We want to eliminate all these `NaN` values from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14394, 18)\n",
      "(14394, 18)\n"
     ]
    }
   ],
   "source": [
    "# Lets check first the dimesions of df before dropping `NaN` values. Use the .shape feature. \n",
    "print(df.shape)\n",
    "\n",
    "# Use the dropna() method to eliminate all the NaN values, and overwrite the same dataframe with the result. \n",
    "# Note: dropna() by default removes all rows containing at least one NaN. \n",
    "df =  df.dropna()\n",
    "#Tested df to ensure there is no NaN\n",
    "# Check the new dimesions of our dataframe. \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2f. Filter the data so that we only see whose apps that have been reviewed at least once\n",
    "\n",
    "Apps that haven't been reviewed yet can't help us solve our brief. \n",
    "\n",
    "So let's check to see if any apps have no reviews at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "App                0\n",
       "Category           0\n",
       "Rating             0\n",
       "Reviews            0\n",
       "Size               0\n",
       "Installs           0\n",
       "Type               0\n",
       "Price              0\n",
       "Content Rating     0\n",
       "Genres             0\n",
       "Last Updated       0\n",
       "Current Ver        0\n",
       "Android Ver        0\n",
       "platform           0\n",
       "ipadSc_urls.num    0\n",
       "lang.num           0\n",
       "vpp_lic            0\n",
       "platform           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset your df to pick out just those rows whose value for 'Reviews' is equal to 0. \n",
    "# Do a count() on the result. \n",
    "df[df['Reviews'] == 0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "929 apps do not have reviews, we need to eliminate these points!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate the points that have 0 reviews.\n",
    "# An elegant way to do this is to assign df the result of picking out just those rows in df whose value for 'Reviews' is NOT 0.\n",
    "df = df[df['Reviews'] != 0]\n",
    "#df - Tested df to observe results for 'Reviews' with no 0 values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2g. Summarize the data visually and analytically (by the column `platform`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need to solve our brief is a summary of the `Rating` column, but separated by the different platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Grouper for 'platform' not 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-6b4e204db033>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Finally, call describe() on the result. We can do this in one line, but this isn't necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#df.groupby(by=_ _ _)['Rating'].describe()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'platform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Rating'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed)\u001b[0m\n\u001b[0;32m   5808\u001b[0m             \u001b[0mgroup_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5809\u001b[0m             \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5810\u001b[1;33m             \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5811\u001b[0m         )\n\u001b[0;32m   5812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated)\u001b[0m\n\u001b[0;32m    407\u001b[0m                 \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                 \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m                 \u001b[0mmutated\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmutated\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m             )\n\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             )\n\u001b[1;32m--> 625\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m             \u001b[1;32melse\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, index, grouper, obj, name, level, sort, observed, in_axis)\u001b[0m\n\u001b[0;32m    343\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ndim\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m                     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Grouper for '{t}' not 1-dimensional\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m                 if not (\n",
      "\u001b[1;31mValueError\u001b[0m: Grouper for 'platform' not 1-dimensional"
     ]
    }
   ],
   "source": [
    "# To summarize analytically, let's use the groupby() method on our df.\n",
    "# For its parameters, let's assign its 'by' parameter 'platform', and then make sure we're seeing 'Rating' too. \n",
    "# Finally, call describe() on the result. We can do this in one line, but this isn't necessary.\n",
    "#df.groupby(by=_ _ _)['Rating'].describe()\n",
    "df.groupby(by='platform')['Rating'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! Our means of 4.049697 and 4.191757 don't **seem** all that different! Perhaps we've solved our brief already: there's no significant difference between Google Play app reviews and Apple Store app reviews. We have an ***observed difference*** here: which is simply (4.191757 - 4.049697) = 0.14206. This is just the actual difference that we observed between the mean rating for apps from Google Play, and the mean rating for apps from the Apple Store. Let's look at how we're going to use this observed difference to solve our problem using a statistical test. \n",
    "\n",
    "**Outline of our method:**\n",
    "1. We'll assume that platform (i.e, whether the app was Google or Apple) really doesn’t impact on ratings. \n",
    "\n",
    "\n",
    "2. Given this assumption, we should actually be able to get a difference in mean rating for Apple apps and mean rating for Google apps that's pretty similar to the one we actually got (0.14206) just by: \n",
    "a. shuffling the ratings column, \n",
    "b. keeping the platform column the same,\n",
    "c. calculating the difference between the mean rating for Apple and the mean rating for Google. \n",
    "\n",
    "\n",
    "3. We can make the shuffle more useful by doing it many times, each time calculating the mean rating for Apple apps and the mean rating for Google apps, and the difference between these means. \n",
    "\n",
    "\n",
    "4. We can then take the mean of all these differences, and this will be called our permutation difference. This permutation difference will be great indicator of what the difference would be if our initial assumption were true and platform really doesn’t impact on ratings. \n",
    "\n",
    "\n",
    "5. Now we do a comparison. If the observed difference looks just like the permutation difference, then we stick with the claim that actually, platform doesn’t impact on ratings. If instead, however, the permutation difference differs significantly from the observed difference, we'll conclude: something's going on; the platform does in fact impact on ratings. \n",
    "\n",
    "\n",
    "6. As for what the definition of *significantly* is, we'll get to that. But there’s a brief summary of what we're going to do. Exciting!\n",
    "\n",
    "If you want to look more deeply at the statistics behind this project, check out [this resource](https://www.springboard.com/archeio/download/4ea4d453b0b84014bcef287c50f47f00/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also get a **visual summary** of the `Rating` column, separated by the different platforms. \n",
    "\n",
    "A good tool to use here is the boxplot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the boxplot() method on our df.\n",
    "# Set the parameters: by = 'platform' and column = ['Rating'].\n",
    "df.boxplot(by=_ _ _, column =_ _ _, grid=False, rot=45, fontsize=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the same information as in the analytical summary, but with a boxplot. Can you see how the boxplot is working here? If you need to revise your boxplots, check out this this [link](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
